<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Monte-Carlo and Metropolis Hastings</title>

    <!-- MathJax for rendering math expressions -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']]
            }
        };
    </script>

    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
        }
        h1, h2, h3 {
            margin-bottom: 10px;
        }
        .equation-block {
            margin: 20px 0;
            text-align: center;
        }
        p {
            line-height: 1.6;
        }
        .figure {
            text-align: center;
        }
        .figure img {
            width: 50%;  /* Reduce the width of images to 50% of the container width */
            height: auto;
        }
    </style>
</head>
<body>

<h1>Monte-Carlo and Metropolis Hastings</h1>
<p>This is a powerful algorithm to estimate target quantities of the form:</p>

<div class="equation-block">
$$
E_{\pi}(g) = \int g(x) \pi(x) \, dx
$$
</div>

<p>which are drawn from a distribution (defined by the pdf $\pi(\cdot)$) that is difficult to sample from. However, this target distribution must be easy to evaluate at a given point up to an unknown constant. This flexibility related to the unknown constant is much appreciated since intractable normalizing constants are quite common.</p>

<p>Monte-Carlo Metropolis Hastings makes use of the rejection sampling (Acceptance/Rejection Method). However, it additionally constructs a Markov chain that moves towards the target density. For high dimensions, this is advantageous over simple rejection sampling. For low dimensions where simple rejection sampling is efficient, the latter is the better method, since, contrary to the Markov chain sampling, independent samples are obtained.</p>

<h2>Rejection Sampling</h2>
<p>Given \( M\lambda(x) \geq \pi(x) \), one first obtains a sample $x$ from a density \( x \sim \lambda(x) \), different from the target ($\pi(x)$), where \( M \) is a scalar. Then one obtains a sample \( u \) from a uniform distribution \( U[0,1] \) and accepts the realization \( x \) from \( \lambda(x) \) if:</p>

<div class="equation-block">
$$
u \leq \frac{\pi(x)}{M\lambda(x)}
$$
</div>

<h3>Probability of Accepting the Sample from $\lambda(x)$</h3>
<p>The probability is:</p>

<div class="equation-block">
$$
\Pr\left( u \leq \frac{\pi(x)}{M\lambda(x)} \bigg| x \right)
$$
</div>

<p>This probability can be calculated as:</p>

<div class="equation-block">
$$
\frac{\pi(x)}{M\lambda(x)} \int \lambda(x) dx = \frac{1}{M}
$$
</div>

<p>In practice, \( M\lambda(x) \) has to be a good cover of \( \pi(x) \), but its choice is difficult in high dimensions.</p>

<h3>Proof of Correctness</h3>
<p>Recall that if \( A \) is the event 'the sample from \( \lambda \) is accepted', then:</p>

<div class="equation-block">
$$
\Pr(A) = M^{-1}
$$
</div>

<p>so that:</p>

<div class="equation-block">
$$
\Pr(x|A) = \frac{\Pr(x \cap A)}{\Pr(A)} = M \Pr(x \cap A)
$$
</div>

<p>The infinitesimal probability of generating and accepting $x$ using rejection sampling is:</p>

<div class="equation-block">
$$
\Pr(x \cap A) = \lambda(x) dx \, \Pr\left(U \leq \frac{\pi(x)}{M \lambda(x)} \right) = \frac{\lambda(x) dx \, \pi(x)}{M \lambda(x)}
$$
</div>

<p>Hence, we can conclude that:</p>

<div class="equation-block">
$$
\Pr(x|A) = M \frac{\lambda(x) dx \, \pi(x)}{M \lambda(x)} = \pi(x) dx
$$
</div>

<p>This concludes the proof of correctness.</p>

<h2>Markov Chain Metropolis Hastings</h2>
<p>The target is:</p>

<div class="equation-block">
$$
E_{\pi}(g) = \int g(x) \pi(x) \, dx
$$
</div>

<p>which can be estimated as:</p>

<div class="equation-block">
$$
E_{\pi}(g) \approx \frac{1}{n} \sum_{i=1}^{n} g(x_i)
$$
</div>

<p>where $x_1, x_2, \ldots, x_n$ are non-independent realizations from $\pi$. Consider the transition kernel of a stationary Markov chain. Assume \( X_{t-1} \) has probability density \( \pi_{t-1} \). If \( \pi_t \) is the probability density of \( X_t \), one has:</p>

<div class="equation-block">
$$
\pi_t(a) = \int k(a, x) \pi_{t-1}(x) \, dx
$$
</div>

<div class="figure">
    <img src="markov-chain-transition/markov-chain-transition.png" alt="Markov Chain with transition kernel" />
</div>

<p>$\pi$ is an invariant probability density if:</p>

<div class="equation-block">
$$
\pi(a) = \int k(a, x) \pi(x) \, dx
$$
</div>

<p>Let \( p \) be an invariant density for the chain.</p>

<h3>Irreducibility</h3>
<p>The chain is <strong>irreducible</strong> if, for any \( x \) and \( A \in \mathcal{B} \) with \( p(A) > 0 \), there exists \( t > 0 \) such that:</p>

<div class="equation-block">
$$
\Pr(X_t \in A \mid X_0 = x) > 0.
$$
</div>

<p>Let \( \{X_t\} \) be an irreducible Markov chain having \( p \) as an invariant density. One has:</p>

<div class="equation-block">
$$
\lim_{n \to \infty} \frac{1}{n} \sum_{t=0}^{n} g(X_t) = E_{\pi}(g)
$$
</div>

<p>for any initial state (except for a set of probability zero).</p>

<h3>Metropolis Hasting Algorithm</h3>
<p>The Metropolis Hasting Algorithm constructs a Markov chain whose invariant distribution is the target distribution. By transitioning from sample to sample according to the transition kernel, it ensures that after many iterations, the samples are obtained from the invariant target distribution.</p>

<p>The algorithm proceeds as follows:</p>

<ul>
    <li>Propose a new sample \( c \), where \( q(\cdot \mid x) \) is the proposal density of the chain:
        <div class="equation-block">
        $$ c \sim q(\cdot \mid x) $$
        </div>
    </li>
    <li>With a certain probability \( a(c, x) \), accept the candidate \( c \), i.e., \( X_{t+1} = c \).</li>
    <li>Otherwise, \( X_{t+1} = x \).</li>
</ul>

<h3>Acceptance Probability</h3>
<p>If the acceptance probability is given by:</p>

<div class="equation-block">
$$
\alpha(c, x) = \min \left( 1, \frac{\pi(c) q(x \mid c)}{\pi(x) q(c \mid x)} \right)
$$
</div>

<p>then $\pi$ becomes the invariant density of the generated Markov chain.</p>

<h3>Detailed Balance Condition</h3>
<p>The detailed balance condition, which must be fulfilled for the algorithm to work, is:</p>

<div class="equation-block">
$$
\pi(X_t) q(X_{t+1} \mid X_t) \alpha(X_{t+1}, X_t) = \pi(X_{t+1}) q(X_t \mid X_{t+1}) \alpha(X_t, X_{t+1})
$$
</div>

<p>Let us examine if it holds:</p>

<h4>Group 1:</h4>
<p>If:</p>

<div class="equation-block">
$$
\frac{\pi(X_{t+1}) q(X_t \mid X_{t+1})}{\pi(X_t) q(X_{t+1} \mid X_t)} < 1
$$
</div>

<p>This implies:</p>

<div class="equation-block">
$$
\alpha(X_{t+1}, X_t) = \frac{\pi(X_{t+1}) q(X_t \mid X_{t+1})}{\pi(X_t) q(X_{t+1} \mid X_t)}
$$
</div>

<p>and:</p>

<div class="equation-block">
$$
\alpha(X_t, X_{t+1}) = 1
$$
</div>

<h4>Group 2:</h4>
<p>If:</p>

<div class="equation-block">
$$
\frac{\pi(X_t) q(X_{t+1} \mid X_t)}{\pi(X_{t+1}) q(X_t \mid X_{t+1})} < 1
$$
</div>

<p>This implies:</p>

<div class="equation-block">
$$
\alpha(X_t, X_{t+1}) = \frac{\pi(X_t) q(X_{t+1} \mid X_t)}{\pi(X_{t+1}) q(X_t \mid X_{t+1})}
$$
</div>

<p>and:</p>

<div class="equation-block">
$$
\alpha(X_{t+1}, X_t) = 1
$$
</div>

<p>Thus the balance equation follows for both groups.</p>

<h3>Kernel of the Chain</h3>
<p>The kernel of the chain is:</p>

<div class="equation-block">
$$
k(X_{t+1} \mid X_t) = q(X_{t+1} \mid X_t) \alpha(X_{t+1}, X_t) + \delta(X_{t+1} = X_t) \left( 1 - \int q(c \mid X_t) \alpha(c, X_t) \, dc \right)
$$
</div>

<p>which, together with the balance equation, implies:</p>

<div class="equation-block">
$$
\pi(X_t) k(X_{t+1} \mid X_t) = \pi(X_{t+1}) k(X_t \mid X_{t+1})
$$
</div>

<p>and:</p>

<div class="equation-block">
$$
\int  \pi(X_t) k(X_{t+1} \mid X_t) \, dX_t = \pi(X_{t+1}) \int k(X_t \mid X_{t+1}) \, dX_t
$$
</div>

<p>Thus:</p>

<div class="equation-block">
$$
\int  \pi(X_t) k(X_{t+1} \mid X_t) \, dX_t = \pi(X_{t+1})
$$
</div>

<p>since:</p>

<div class="equation-block">
$$
\int k(X_t \mid X_{t+1}) \, dX_t = 1
$$
</div>

<p>$\pi$ is indeed the invariant density.</p>

<h3>Preliminaries</h3>
<ul>
    <li>We must be able to evaluate the target density \( \pi \), apart from a normalization factor.</li>
    <li>The algorithm works for any \( q(\cdot \mid \cdot) \) (if the chain is irreducible), but in practice, the choice of \( q \) is crucial.</li>
</ul>

<h3>Random-Walk Proposals</h3>
<p>Often, it is useful to adopt random-walk proposals:</p>

<div class="equation-block">
$$
q(c \mid x) = f(c - x) = q(x \mid c)
$$
</div>

<p>where:</p>

<div class="equation-block">
$$
c = x_t + \epsilon, \quad \epsilon \sim N(0, \Sigma)
$$
</div>

<p>which implies:</p>

<div class="equation-block">
$$
q(c \mid x) = N(x, \Sigma)
$$
</div>

<p>\( \Sigma \) provides information on how to move locally around the current point and the acceptance probability becomes:</p>

<div class="equation-block">
$$
\alpha(c, x) = \min \left( 1, \frac{\pi(c)}{\pi(x)} \right)
$$
</div>


</body>
</html>
