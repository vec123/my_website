<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Algorithms on Networks</title>

    <!-- MathJax for rendering math expressions -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']]
            }
        };
    </script>

    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
        }
        h1, h2, h3 {
            margin-bottom: 10px;
        }
        .equation-block {
            margin: 20px 0;
            text-align: center;
        }
        p {
            line-height: 1.6;
        }
    </style>
</head>
<body>

<h1>Reservoir Sampling</h1>
<p>Reservoir Sampling is an algorithm to sample from a potentially infinite stream $\Sigma$. Each element in the sample has the same uniform probability of being picked and the sample has size $M$ always. Getting samples from infinite (or very large) streams has several applications. For example, sampling websites from the net, sampling metro passengers, sampling visitors, and many more. The context in which I learned about this algorithm was related to sampling edges from a graph with many edges â€” many more than fit into RAM. To estimate the number of triangles (or other motifs) in the graph, one needs to look at the edges. If one cannot look at all of them, at least some are required. Each edge must be sampled with equal probabilities.</p>

<p>The algorithm goes as follows:</p>

<h2>Algorithm</h2>

<ol>
    <li>Initialize</li>
    <ul>
        <li>$t \leftarrow 0$</li>
        <li>$S \leftarrow \emptyset$</li>
    </ul>
</ol>

<p>For each $x_t \in \Sigma$:</p>

<ol>
    <li>$t \leftarrow t + 1$</li>
    <li>If $t \leq M$:</li>
    <ul>
        <li>$S \leftarrow S \cup x_t$</li>
        <li>Else:</li>
        <ul>
            <li>If $SampleElement\left(\frac{M}{t}\right)$:</li>
            <ul>
                <li>Pick $x_i$ from $S$ uniformly at random (probability $\frac{1}{M}$)</li>
                <li>$S \leftarrow S \setminus \{x_i\}$</li>
                <li>$S \leftarrow S \cup \{x\}$</li>
            </ul>
        </ul>
    </ul>
</ol>

<h2>Proposition</h2>
<p><strong>Proposition:</strong></p>
<ol>
    <li><strong>i)</strong> $\Pr(x_i \in S) = \frac{M}{t}$ for all $i$ and $t$</li>
</ol>

<p>By induction:</p>

<div class="equation-block">
$$ t = M \Rightarrow \Pr(x \in S) = 1 $$
</div>

<p>Now $t \geq M$:</p>

<div class="equation-block">
$$ \Pr(x_i \in S ) = \Pr(x_i \in S \text{ and } A ) + \Pr(x_i \in S  \text{ and } \overline{A}) $$
</div>

<p>and:</p>

<div class="equation-block">
$$ \Pr(x_i \in S \text{ and } A )  = \Pr(x_i \in S \mid A ) \Pr(A) $$
$$ \Pr(x_i \in S \text{ and } \overline{A} )  = \Pr(x_i \in S \mid \overline{A} ) \Pr(\overline{A}) $$
</div>

<p>Note:</p>

<div class="equation-block">
$$ \Pr(A) = \frac{M}{t} $$
</div>

<p>This is the probability that the element $x_i$ is removed and $x_t$ is added to the samples. $\Pr(\overline{A})  = 1- \Pr(A)$.</p>

<div class="equation-block">
$$ \Pr(x_i \in S \mid A )  = \frac{M}{t-1} \left(1-\frac{1}{M}\right), $$
</div>

<p>where $\frac{M}{t-1}$ comes by induction and $1-\frac{1}{M}$ is the probability that $x_i$ was not removed due to event $A$.</p>

<div class="equation-block">
$$ \Pr(x_i \in S \mid \overline{A} )  = \frac{M}{t-1}. $$
</div>

<p>Thus:</p>

<div class="equation-block">
$$ \Pr(x_i \in S ) =  \frac{M}{t-1} \left(1-\frac{1}{M}\right)\frac{M}{t} + \frac{M}{t-1}\left(1-\frac{M}{t}\right) = \frac{M}{t}. $$
</div>

<p>It is trivial that $|S| = M$ for all $t$.</p>

</body>
</html>
