<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Score Matching</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
        }
        h1, h2, h3, h4, h5, h6 {
            color: #2c3e50;
        }
        p {
            line-height: 1.6;
        }
        .equation {
            text-align: center;
            margin: 20px 0;
        }
        .equation span {
            font-family: "Courier New", monospace;
            background-color: #f9f9f9;
            display: inline-block;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 5px;
        }
        .highlight {
            color: red;
        }
        .author-date {
            font-style: italic;
            margin-bottom: 20px;
        }
    </style>
</head>
<body>

    <h1>Score Matching</h1>
    <p class="author-date">vic-bayer, October 2024</p>

    <h2>Introduction</h2>
    <p>Score-matching is a method for likelihood maximization applied to models of the form:</p>
    <div class="equation">
        <span>p<sub>θ</sub>(x) = <i>𝑡𝑖𝑙𝑑𝑒</i>(x) / Z<sub>θ</sub></span>
    </div>
    <p>where <i>Z<sub>θ</sub> = ∫𝑡𝑖𝑙𝑑𝑒(x) dx</i> is generally intractable normalization. Energy models have promise here, approximating the integral via Langevin.</p>

    <h2>Problem Setup</h2>
    <div class="equation">
        <span>
            Score refers to <i>∇ log p(x, θ)</i>.
            Regularity assumptions assume <i>∇ log q→0  |x|_2→∞ </i>.
        </span>
    </div>

    <h2>Energy-Based Models</h2>
    <p>An example of such a model is an energy-based model which enjoys a very flexible parameterization as a Boltzmann distribution (also called Gibbs distribution) with the form:</p>
    <div class="equation">
        <span>p<sub>θ</sub>(x) = e<sup>-f<sub>θ</sub>(x)</sup> / ∫ e<sup>-f<sub>θ</sub>(x)</sup> dx</span>
    </div>
    <p>Here, <i>f<sub>θ</sub>(x)</i> denotes the energy of the distribution in analogy to the Boltzmann distribution. In the context of energy-based model optimization, <i>∫ e<sup>-f<sub>θ</sub>(x)</sup> dx</i> is often approximated using Monte Carlo methods, or more specifically, Langevin dynamics. This is generally computationally expensive, although in low dimensions, it might be amenable to parallelization via rejection sampling.</p>

    <h2>Score Matching Methodology</h2>
    <p>The idea is that:</p>
    <div class="equation">
        <span>∇<sub>x</sub> log p(x, θ) = ∇<sub>x</sub> log [e<sup>p<sub>θ</sub>(x)</sup> / ∫ e<sup>p<sub>θ</sub>(x)</sup> dx] = ∇<sub>x</sub> p<sub>θ</sub>(x) - ∇<sub>x</sub> Z<sub>θ</sub> = ∇<sub>x</sub> p<sub>θ</sub>(x)</span>
    </div>
    <p>In essence, the score function does not depend on the intractable integral while still containing information about the distribution. As the name suggests, score matching aims at matching the gradient of the empirical data density <i>q(·)</i> with the gradient of the model density <i>p(·, θ)</i>, leading to an optimization of the form:</p>
    <div class="equation">
        <span>θ<sub>opt</sub> = argmin<sub>θ</sub> (1/2) E<sub>q</sub> ||∇<sub>x</sub> log q(x) - ∇<sub>x</sub> log p(x, θ)||<sub>2</sub><sup>2</sup></span>
    </div>

    <h2>Further Analysis</h2>
    <p>Consider the term:</p>
    <div class="equation">
        <span>(1/2) ||∇<sub>x</sub> log q(x) - ∇<sub>x</sub> log p(x, θ)||<sub>2</sub><sup>2</sup> = (1/2) (∇<sub>x</sub> log q(x))<sup>2</sup> +
            <h2>Energy-Based Models</h2>
            <p>An example of such a model is an energy-based model which enjoys a very flexible parameterization as a Boltzmann distribution (also called Gibbs distribution) with the form:</p>
            <div class="equation">
                <span>p<sub>θ</sub>(x) = e<sup>-f<sub>θ</sub>(x)</sup> / ∫ e<sup>-f<sub>θ</sub>(x)</sup> dx</span>
            </div>
            <p>Here, <i>f<sub>θ</sub>(x)</i> denotes the energy of the distribution in analogy to the Boltzmann distribution. In the context of energy-based model optimization, <i>∫ e<sup>-f<sub>θ</sub>(x)</sup> dx</i> is often approximated using Monte Carlo methods, or more specifically, Langevin dynamics. This is generally computationally expensive, although in low dimensions, it might be amenable to parallelization via rejection sampling.</p>
        
            <h2>Score Matching Methodology</h2>
            <p>The idea is that:</p>
            <div class="equation">
                <span>∇<sub>x</sub> log p(x, θ) = ∇<sub>x</sub> log [e<sup>p<sub>θ</sub>(x)</sup> / ∫ e<sup>p<sub>θ</sub>(x)</sup> dx] = ∇<sub>x</sub> p<sub>θ</sub>(x) - ∇<sub>x</sub> Z<sub>θ</sub> = ∇<sub>x</sub> p<sub>θ</sub>(x)</span>
            </div>
            <p>In essence, the score function does not depend on the intractable integral while still containing information about the distribution. As the name suggests, score matching aims at matching the gradient of the empirical data density <i>q(·)</i> with the gradient of the model density <i>p(·, θ)</i>, leading to an optimization of the form:</p>
            <div class="equation">
                <span>θ<sub>opt</sub> = argmin<sub>θ</sub> (1/2) E<sub>q</sub> ||∇<sub>x</sub> log q(x) - ∇<sub>x</sub> log p(x, θ)||<sub>2</sub><sup>2</sup></span>
            </div>
        
            <h2>Further Analysis</h2>
            <p>Consider the term:</p>
            <div class="equation">
                <span>(1/2) ||∇<sub>x</sub> log q(x) - ∇<sub>x</sub> log p(x, θ)||<sub>2</sub><sup>2</sup> = (1/2) (∇<sub>x</sub> log q(x))<sup>2</sup> + (1/2) (∇<sub>x</sub> ∇<sub>x</sub> log p(x, θ))<sup>2</sup> - (1/2) ∇<sub>x</sub> log q(x) ∇<sub>x</sub> log p(x, θ)</span>
            </div>
            <p>The first term does not depend on <i>θ</i>, so it is not relevant for the optimization problem.</p>
        
            <h2>Expectation of the Cross-Term</h2>
            <p>Now consider:</p>
            <div class="equation">
                <span>E<sub>q</sub> [-∇<sub>x</sub> log q(x) ∇<sub>x</sub> log p(x, θ)] = ∫ -∇<sub>x</sub> log q(x) ∇<sub>x</sub> log p(x, θ) q(x) dx</span>
            </div>
            <p>This simplifies using integration by parts to:</p>
            <div class="equation">
                <span>∫ -∇<sub>x</sub> q(x) ∇<sub>x</sub> log p(x, θ) dx = -lim<sub>b→∞</sub> ∇<sub>x</sub> log p(b, θ) q(b) + lim<sub>a→-∞</sub> ∇<sub>x</sub> log p(a, θ) q(a) + ∫ ∇<sub>x</sub><sup>2</sup> p(x, θ) q(x) dx</span>
            </div>
            <p>The last equality follows from integration by parts. Here, Hyvärinen et al. make the regularity assumptions that:</p>
            <div class="equation">
                <span>∇<sub>x</sub> log p(x, θ) q(x) → 0 when ||x||<sub>2</sub> → ∞</span>
            </div>
        
            <h2>Limitations and Regularity Assumptions</h2>
            <p>These assumptions do not hold for general point processes, such as the Poisson process or Hawkes process, which do not necessarily decay sufficiently fast at the boundary. To alleviate this, a weight function enforcing decay can be introduced, as discussed in <span class="highlight">"Is Score Matching Suitable for Estimating Point Processes?"</span> Furthermore, nominal score matching is not suitable for autoregressive models, which is also addressed in the same work.</p>
        
            <h2>Optimization Problem</h2>
            <p>Assuming the regularity assumptions hold, the optimization problem can be rewritten as:</p>
            <div class="equation">
                <span>θ<sub>opt</sub> = argmin<sub>θ</sub> E<sub>q</sub> [Tr(∇<sub>x</sub><sup>2</sup> p(x, θ)) - (1/2) ||∇<sub>x</sub> log p(x, θ)||<sub>2</sub><sup>2</sup>]</span>
            </div>
            <p>If the data distribution is in the model class, this optimization yields the optimal value.</p>
        
        </body>
        </html>
        